---
title: "Manipulating data"
author: "Vinay Swamy"
date: "9/4/2020"
output:
  ioslides_presentation: 
    widescreen: true
---

<style>
slides > slide {
  overflow-x: auto !important;
  overflow-y: auto !important;
}
</style>
```{r setup, echo=FALSE}
knitr::opts_chunk$set(fig.height = 3, fig.width =5)
options(warn = -1)
```

```{r echo =F}
options(tibble.print_max = 5)
```

## Review 

## Data Types
- We have covered 3 data types in R. What are they, and what is each one used for 

## Data Types
- `numeric` - used for numerical data ; `character` used for strings/text, factor - alternative to `character`, used in plotting.

## List vs Vector

- What is the major difference between a list and a vector

## List vs Vector

- vectors must be a single data type; lists can contain multiple data types, and can contain multiple data structures, IE lists of lists, lists of dataframes 


## Dataframes
- what type of data are dataframes used for 

## Dataframes
- tabular data like spreadsheets or csv's 

## Indexing

- how does indexing work for a vector
- how does indexing work for a  list
- how does indexing work for a  dataframe?

## Indexing

- vector
    - `vec[i]`, for the ith  element in a vector
    - `vec[i:j]` to select all elements between i and j 
- list
    - `lst[[i]]`, for the ith  element in a list
    - `lst[i:j]`, to select all elements between i and j 
- dataframe 
    - `df[, i]` to select column number i; `df[i, ]
    - `df[i,]` to select row number i; 
    - `df[i:j, ]` / `df[,i:j]` for selecting a range of rows/columns 
    
- if an object has names, values can also be accessed by their name, instead of their numerical index

##  ggplot

- what are the three major components of a `ggplot`?

##  ggplot

-  base `ggplot` layer, `geom` layer, `theme` layer

## data usually does not come with a bow on top

- almost all real world data won't be ready for plotting; usually steps to *clean* and *tidy* the data are required
- clean data as all the data with the right data types, IE numbers are `numeric`, strings are `characters`
- tidy data has data organized such that each complete row is a unique observation.
- thankfully there are quite a bit of resources for doing this within R

## the Tidyverse

- the tidyverse is a collection of packages that provide *fast, well documented* functions for data science.
- This includes reading and writing data, organizing and "tidying" data, and plotting data
```{r}
library(tidyverse)
```

## the Tidyverse
- tibble: a new data type analogous to a `data.frame`, but with more consistent indexing, and no type coercion
- dplyr: a series of functions for subsetting, filtering, changing, and summarizing dataframes/tibbles
- tidyr: functions for tidying data(more on that later)
- stringr: library for efficiently working with strings
- readr: efficiently read/write data
- forcats: library for efficiently working with factors
- purrr: adds common programming methods from other languages into
- using `library(tidyverse)` makes it easy to load these all at once; but you can load them individually if you choose

## the `readr` package
- easiest to use, this is for reading external data *into* R, and writing data within R *to* the disk;


## reading data 
- generally tabular data is arranges where each element within a row is separated by a delimiter, and whole rows are separated by a newline
- the delimiter are commonly tabs `\t`, or commas, `,`. The delimiter is reflected in the file extensions of tabular data, IE "tab separated values" is a `.tsv` file, and "comma separated values are `.csv`
- the `read_...` functions all work the same way - just provide the name of the file

## reading data 

```{r}
data <- read_tsv('dummy.tsv')
data
```

## reading data 
```{r}
data <- read_csv('dummy.csv')
data
```

## writing data
- writing data works similarly to reading it; just provides a `tibble` and a filename to write to
```{r}
write_tsv(head(mtcars), path =  'dummy.tsv')
write_csv(head(iris), path = 'dummy.csv')
write_delim(head(airquality) ,'dummy.txt', delim ='|')
```

## reading data 
- use read_delim to use a custom delimiter
```{r}
data <- read_delim('dummy.txt', delim = '|')
data
```

## the filesystem
- In all computers are arranged as a series of nested folders, with files in each folder. 
- the location of a file on your computer is called its `path`

## file paths 
- This is an absolute file path `/Users/swamyvs/personal/BIOF076-Visualization-with-R/Using-The-Tidyverse` 
- All paths start with '/' on unix(macOS/linux) systems. 
- On Windows, absolute paths always start with the drive name: `C:/User/local...`
- No matter where you are, absolute paths always point to the same location

## the working directory
- the working directory is the location on your computer that R looks for files in, or writes files too.
- your can find the working directory using the `getwd` function
```{r}
getwd()
```

## the working directory
-each `/` represents a different folder. In this, R is looking and writing to the `day_2` directory
-you can change the working directory by using `setwd`(this doesn't work super great inside an R notebook)
```{r, warning=FALSE}
setwd('/Users/swamyvs/')
```

## the working directory
- use the `dir` function to show what files and folders are in the the working directory
```{r, warning=FALSE}
setwd("/Users/swamyvs/personal/BIOF076-Visualization-with-R/Using-The-Tidyverse/")
dir()
```



##  local filepaths 
- files paths don't have to absolute
```{r}
getwd()
```

##  local filepaths 

```{r}
setwd('../')
read_csv('Using-The-Tidyverse/dummy.csv')
```

##  local filepaths 
- here, I set the working directory up on level with `../`,  which means "go up one level", and the file `dummy.tsv` could not be found.
- but if I use the absolute path as the input filename, it works no matter what the directory is.

## working directorys  in notebooks
- The working directory for a notebook is fixed to what every folder the notebook is saved in. 
- If you change the working directory within a notebook cell, it applies *only* to that cell. 

## filepaths summary
- always be careful of your filepaths; whenever possible use the absolute paths. 
- When typing a file path in Rstudio, use `tab` to autocomplete the paths.

## the `tibble`
- `tibble` is a play on the word "table"
- the is the tidyverse's reimplimentation of a data frame
- the key differences are that tibbles don't have rownames, and that tibbles always maintain strings as `characters`

## the `tibble`
- `tibbles` are also a little easier to print out
```{r}
tibble(iris)
```

## the `tibble` package
- only a the first 10 or so rows are printed out, not all columns are printed out either 

## the `tibble`
- use `tibble` just like `data.frame`
```{r}
tb <- tibble(x=rnorm(100), y=rnorm(100) )
head(tb)
```

## the `tibble` package
- the `as_tibble` function will coerce existing data frames to tibbles

```{r}
class(iris)
```

## the `tibble` package
```{r}
iris_tbl <- as_tibble(iris)
class(iris_tbl)
```

## the `dplyr` package
- "dplyr stands for "data plier", and is a package centered around manipulating tabular data. It provides efficient "verbs" to subset data, change it , and filter it. 
- There are a large number of useful functions that are within the package, but we're going to focus on a core few. 
- None of the `dplyr` functions modify data in-place, so always must store the output in a new variable if you want to use the result again 

## `select`

- `select` - subset dataframes based on column names; select always returns a data frame regardless of columns
```{r}
data(mpg)
mpg
```

## `select`

```{r}
select(mpg, model)
```

## `select`
- note that i did not use quotes for the `model` column; like `ggplot`, dplyr support quasi-quotation, so column names can be used with out quoting them 
- you can select multiple columns, either by specifying a specific column, or a range
```{r}
select(mpg, model, class)
```

## `select`
```{r}
select(mpg, displ:trans)
```

## `select`
- `select` can also be used to drop columns
```{r}
select(mpg, -manufacturer, -class)
```

## the `filter` function
- `filter` allows you to find data that match certain conditions, by using logical filtering
```{r}
data("airquality")
airquality <- tibble(airquality)
airquality
```

## the `filter` function
```{r}
df <-  filter(airquality, Month == 5)
df
```

## the `filter` function
- multiple logical filters can be passed
```{r}
df <- filter(airquality, Month == 5, Wind  > 10)
df
```

## the `filter` function
- functions returning a logical vector can also be used
```{r}
df <- filter(airquality, !is.na(Solar.R))
df
```

## the `mutate` function
- the mutate function lets you add columns to the data, or change existing ones 
```{r}
mutate(airquality, Ozone = -1)
```

## the `mutate` function
```{r}
df <- mutate(airquality, temp_zone = ifelse(Temp > 75, 'HIGH', 'LOW')) 
as_tibble(df)
```


## the `arrange` function
-  this function lets you sort data

```{r}
iris <- as_tibble(iris)
arrange(iris, Sepal.Width)
```


## the `arrange` function
- note that this sorts is in ascending order. for descending order, wrap the column name in the `desc` function
```{r}
arrange(iris, desc(Sepal.Width))
```

## the `pull` function
- the `pull` function allows you to extract a column from a data frame, similar to the `$` operator 
```{r}
pull(iris, Sepal.Width) %>% head
```

## `dplyr` functions as "verbs"
- Its best to think of each of these functions as an action or "verb" that we perform on the. 
- For example within the `airquality` data:
" In my data I want to keep only the rows correspond to the months 5, or 6, keep only the temp and species column, and change the month column so that we use the character names for the month instead of the numeric names"

## `dplyr` functions as "verbs"

```{r}
df <- filter(airquality, Month %in% c(5, 6))
df <- select(df, Month, Temp)
df <- mutate(df, Month = ifelse(Month == 5, 'May', 'June'))
df
```

## using pipes

```{r}
df <- filter(airquality, Month %in% c(5, 6))
df <- select(df, Month, Temp)
df <- mutate(df, Month = ifelse(Month == 5, 'May', 'June'))
```

- Looking at this code, we can see that we are performing repeated actions on the same data, where the output of one function is the input for the next function. 
- `dplyr` provides a method for chaining multiple functions together, automatically redirecting the output of one function into an other function, through something called a pipe: ` %>% `

## using pipes

```{r}
df <- filter(airquality, Month %in% c(5, 6)) %>% 
    select( Month, Temp) %>%
    mutate( Month = ifelse(Month == 5, 'May', 'June'))
df
```
- pipes can make it easier to understand your code, and help iteratively build a query or transformation for some data 

## the "`.`" hidden variable in `%>%`
-  when using the `%>%` operator, the output of each function is stored in a temporary variable called `.`
```{r}
iris %>% pull(Sepal.Width) %>% head %>% print
```

## the "`.`" hidden variable in `%>%`
```{r}
iris %>% pull(Sepal.Width) %>% .[1]
```

## lets do some practice

## wide vs long data 

- two common ways for formatting data are "wide" and "long"
```{r}
data("economics")
economics
```
- this is an example of wide data - each data point/ label is date, with multiple observations per date. Data in this format is generally used for building models like regression or machine learning model

## wide vs long data 

```{r include=F}
data("economics_long")
economics_long %>% arrange(date) %>% as_tibble
```
- this is the same data, but in "long format". Here, each row is a distinct measurement; note that the date column is repeated multiple times for different variable. 
- the reason long format is preferred is that it reduces the number of columns in a data set, making it longer instead. 
- remember that each column is a vector under the hood; computationally its more efficient to perform the same operation over a single large vector, rather than a series of smaller vectors/columns

## converting from wide to long
- the `tidyr` package has a useful function called `pivot_longer` that allows you to convert from wide to long

```{r}
economics %>% as_tibble
```

## converting from wide to long
```{r}
economics %>% 
    pivot_longer(cols = c(pop, pce, psavert, uempmed, unemploy),
                 names_to = 'variable', 
                 values_to = 'obs') %>% as_tibble
```

## converting from wide to long

- same thing a different way
```{r}
#every column except the data column
economics %>% pivot_longer(cols = -date,  
                           names_to = 'variable', 
                           values_to = 'obs') %>% as_tibble
```

## grouping and summarizing data 
- we often want to generate summary statistics for subcharacteristics/subpopulations of our data
- for example, calculating the the average value by day in  `economics_long` data. we do this by using the `group_by` and `summarise` functions from `dplyr`

```{r}
economics_long %>% arrange(date) %>% as_tibble
```

## grouping and summarizing data 
```{r}
economics_long %>% 
    group_by(date) %>% 
    summarise(avg_value_per_day = mean(value))
```

- when grouping and summarizing data, always remember that what ever function your use to summaries `mean`, `max`, etc, must return a single value

## merging tabular data
- We've only been working with single data frames/tibbles, but we often will need to combine multiple data.frames together. 
- In its simplest form, this is called binding. functions for this are provided in dplyr: `bind_rows` and `bind_cols`

## merging tabular data
```{r}
dim(iris)
```

## merging tabular data
```{r}
bind_rows(iris, iris) %>% dim
```

## merging tabular data
```{r}
bind_cols(iris, iris) %>% dim
```

## merging uneven tabular data
- more often then not, the data you are trying to combine isn't the same shape, so be a little careful. Thankfully, both `bind_rows` and `bind_cols` have a bit of error checking involved

```{r}
iris_small <- iris[1:5, 1:3]
colnames(iris_small) <- c('a', 'b', 'c')
dim(iris_small)
```

```{r}
dim(iris)
```

## merging tabular data
```{r}
bind_rows(iris, iris_small)
```

## merging tabular data
- `bind_rows` will NOT bind data that has different colnames, even if they are in the same position.

## merging tabular data

```{r, error=T}
cb_iris <- bind_cols( iris_small, iris)
```
- bind cols doesn't work if the data is mismatched. This is because there isn't really a good reason to ever column bind uneven data.

## joining data 
- Often times we *do* want to combine data by merge along columns, but in a more structured way

```{r}
mpg %>% as_tibble
```
## joining data 
- say i went out and figured out which models were gas powered and which ones were diesel
```{r}

model2fuel <- tibble(model= unique(mpg$model), 
       fuel_type = sample(c('gas', 'diesel'), n_distinct(mpg$model) ,replace= T)) 
model2fuel
```
## joining data 

- i want to make plot by gas type for city mileage
```{r}
cty_by_fueltype <-  mpg %>% select(model, cty) %>% left_join(x=., y=model2fuel, by = 'model')
cty_by_fueltype
```
## joining data 

```{r}
ggplot(cty_by_fueltype) + 
  geom_boxplot(aes(x = fuel_type, y=cty, fill = fuel_type), width = .25) + 
  theme_classic()
```

## joining data 
-  joins merge together data frames by 1 or more ID columns, in this case `model`

## types of joins
- *_join( left, right, by..) - merge 2 data frames by common values in a shared column(s)
- `left_join`: keep all values in the left data frame. any values that are in the left, but not the right are kept, with NA values generated in the right df
```{r}
model2fuel[1:2, ] %>% left_join(mpg ,.) %>% filter(!grepl('a4',model)) %>% select(model, fuel_type)

```

## types of joins

```{r}
model2fuel[1:2, ] %>% left_join(mpg) %>% select(model, fuel_type)
```

## types of joins
- `inner_join` : only keep rows that have matching id's in **both** columns; no NA's will be generated, and if nothing matches an empty df is returned
```{r}
model2fuel[1:2, ] %>% inner_join(mpg,.) %>% select(model, fuel_type)
```

## types of joins
- `full_join` joins all rows, as long as there is at least one common values between the join columns
```{r}
model2fuel[1:2, ] %>% full_join(mpg,.) %>% select(model, fuel_type)
```

## duplicate values in joining columns
- be careful when joining columns that have repeated values in columns 

```{r}
a4_only <- filter(mpg, model == 'a4')
dim(a4_only)
```
```{r}

a4_fuel <- filter(model2fuel, model == 'a4') %>% bind_rows(. ,. ,. ,. ,. ,.)
dim(a4_fuel)
```

## duplicate values in joining columns
```{r}
left_join(a4_only, a4_fuel, by= 'model') %>% dim
``` 
- when you have duplicate values in joining columns in *both* data frames, the values will be matched multiple times
- if you're not careful about this, you might make a data-frame that consumes all your memory and crashes R

## duplicate values in joining columns
- the `distinct` function will remove any duplicated rows, and help prevent this 
```{r}
left_join(a4_only, a4_fuel %>% distinct, by= 'model') %>% dim
```


